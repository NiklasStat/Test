<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>R Machine Learning - Kapitel 3</title>

<script src="site_libs/header-attrs-2.24/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/lumen.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My Website</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="bbb1.html">1. Grundlagen Programmierung mit R</a>
</li>
<li>
  <a href="index_2.html">2. Data Science mit R</a>
</li>
<li>
  <a href="index_3.html">3. Machine Learning</a>
</li>
<li>
  <a href="index_4.html">4. Projekte mit R</a>
</li>
<li>
  <a href="test_markdown.html">Testen</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">R Machine Learning - Kapitel 3</h1>

</div>


<div id="einleitung-zu-machine-learning" class="section level1"
number="1">
<h1><span class="header-section-number">1</span> Einleitung zu Machine
Learning</h1>
<p>Machine Learning (ML) in der Statistik bezieht sich auf die
Verwendung von statistischen Methoden und Algorithmen, um Modelle zu
entwickeln, die es Computern ermöglichen, Muster in Daten zu erkennen
und Vorhersagen zu treffen. Das Ziel von ML-Methoden besteht darin, aus
Beispielen zu lernen, um Vorhersagen auf neuen, unbekannten Daten
treffen zu können. Dies geschieht durch die Verwendung von Algorithmen
wie Entscheidungsbaum-Modellen, künstlichen neuronalen Netzen,
Bayes’schen Netzen und Support Vector Machines.</p>
<p>In der Praxis wird Machine Learning in der Statistik für viele
Anwendungen eingesetzt, wie z.B. Bild- und Spracherkennung,
Empfehlungssysteme, Betrugserkennung, medizinische Diagnose und
Vorhersage von Aktienkursen. Die Wahl des geeigneten Algorithmus hängt
von der Art der Daten, der Komplexität des Problems und den verfügbaren
Ressourcen ab.</p>
<p>Supervised und unsupervised Modelle sind zwei grundlegende Kategorien
von Machine-Learning-Modellen.</p>
<div id="supervised-learning" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Supervised
Learning</h2>
<p>Supervised Learning ist eine Methode des maschinellen Lernens, bei
der der Algorithmus trainiert wird, um aus einer gegebenen Menge von
Trainingsdaten zu lernen, die annotiert sind, d.h. bei denen die Ausgabe
oder Zielvariable bekannt ist. Der Algorithmus lernt, indem er die
Beziehung zwischen Eingabe- und Ausgabevariablen modelliert, um
Vorhersagen auf neuen Daten zu treffen. Es werden also Attribute X
benutzt, um eine Zielvariable Y vorherzusagen. Die meisten Supervised
Learning Probleme können einer von zwei Kategorien zugeordnet werden:
Regression oder Klassifikation. Regressionsprobleme haben eine metrische
Zielvariable, Klassifikationsprobleme haben eine kategoriale
Variable.</p>
<p><img
src="images/reg.png"
title="Regression" alt="Regression" /> <img
src="images/klass.png"
title="Klassifikation" alt="Klassifikation" /></p>
</div>
<div id="unsupervised-learning" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Unsupervised
Learning</h2>
<p>Unsupervised Learning ist eine Methode des maschinellen Lernens, bei
der der Algorithmus nicht mit annotierten Trainingsdaten arbeitet.
Stattdessen lernt der Algorithmus, Muster und Strukturen in den Daten zu
erkennen, indem er versucht, sie automatisch zu gruppieren oder zu
segmentieren, um inhärente Beziehungen zu entdecken. Ein Beispiel für
die Anwendung von Unsupervised Learning ist die Segmentierung von Kunden
in Gruppen mit ähnlichem Kaufverhalten. Dabei werden keine annotierten
Daten verwendet, sondern der Algorithmus erkennt die Gemeinsamkeiten in
den Kaufmustern der Kunden und gruppiert sie entsprechend.</p>
<p>Bekannt sind hier vor allem das Clustering und die
Dimensionsreduktion. Bei diesen Modellen ist die Qualitätsüberprüfung
natürlich sehr schwierig, da wir Antwort auf unsere Frage nicht kennen.
Im Gegensatz zu supervised Modellen.</p>
</div>
</div>
<div id="modellierungsverfahren" class="section level1" number="2">
<h1><span class="header-section-number">2</span>
Modellierungsverfahren</h1>
<p>Sich den Machine Learning Modellen anzunähern bedeutet, die Daten
besser kennezulernen. Validierungsprozess durchführen ist ebenso
wichtig, wie die richtigen Features und Outcome Variablen zu wählen. So
ist der Modellierungsprozess kein Sprint, sondern es bedarf vieler
Schritte, um das optimale Modell zu finden.</p>
<div class="float">
<img
src="images/modeling_process.png"
title="ML_Prozess" alt="ML_Prozess" />
<div class="figcaption">ML_Prozess</div>
</div>
<div id="voraussetzungen" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Voraussetzungen</h2>
<pre class="r"><code># Helper packages
library(dplyr)     # for data manipulation</code></pre>
<pre><code>## Warning: Paket &#39;dplyr&#39; wurde unter R Version 4.2.3 erstellt</code></pre>
<pre><code>## 
## Attache Paket: &#39;dplyr&#39;</code></pre>
<pre><code>## Die folgenden Objekte sind maskiert von &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## Die folgenden Objekte sind maskiert von &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>library(ggplot2)   # for awesome graphics</code></pre>
<pre><code>## Warning: Paket &#39;ggplot2&#39; wurde unter R Version 4.2.3 erstellt</code></pre>
<pre class="r"><code># Modeling process packages
library(rsample)   # for resampling procedures</code></pre>
<pre><code>## Warning: Paket &#39;rsample&#39; wurde unter R Version 4.2.3 erstellt</code></pre>
<pre class="r"><code>library(caret)     # for resampling and model training</code></pre>
<pre><code>## Warning: Paket &#39;caret&#39; wurde unter R Version 4.2.3 erstellt</code></pre>
<pre><code>## Lade nötiges Paket: lattice</code></pre>
<pre class="r"><code>library(h2o)       # for resampling and model training</code></pre>
<pre><code>## Warning: Paket &#39;h2o&#39; wurde unter R Version 4.2.3 erstellt</code></pre>
<pre><code>## 
## ----------------------------------------------------------------------
## 
## Your next step is to start H2O:
##     &gt; h2o.init()
## 
## For H2O package documentation, ask for help:
##     &gt; ??h2o
## 
## After starting H2O, you can use the Web UI at http://localhost:54321
## For more information visit https://docs.h2o.ai
## 
## ----------------------------------------------------------------------</code></pre>
<pre><code>## 
## Attache Paket: &#39;h2o&#39;</code></pre>
<pre><code>## Die folgenden Objekte sind maskiert von &#39;package:stats&#39;:
## 
##     cor, sd, var</code></pre>
<pre><code>## Die folgenden Objekte sind maskiert von &#39;package:base&#39;:
## 
##     %*%, %in%, &amp;&amp;, ||, apply, as.factor, as.numeric, colnames,
##     colnames&lt;-, ifelse, is.character, is.factor, is.numeric, log,
##     log10, log1p, log2, round, signif, trunc</code></pre>
<pre class="r"><code># h2o set-up 
h2o.no_progress()  # turn off h2o progress bars
h2o.init()         # launch h2o</code></pre>
<pre><code>## 
## H2O is not running yet, starting it now...
## 
## Note:  In case of errors look at the following log files:
##     C:\Users\nikla\AppData\Local\Temp\RtmpsLbbvj\file4f7448b6453d/h2o_nikla_started_from_r.out
##     C:\Users\nikla\AppData\Local\Temp\RtmpsLbbvj\file4f7472543860/h2o_nikla_started_from_r.err
## 
## 
## Starting H2O JVM and connecting: ........ Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         54 seconds 112 milliseconds 
##     H2O cluster timezone:       Europe/Berlin 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.40.0.1 
##     H2O cluster version age:    8 months 
##     H2O cluster name:           H2O_started_from_R_nikla_ijy204 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   1.95 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     R Version:                  R version 4.2.2 (2022-10-31 ucrt)</code></pre>
<pre><code>## Warning in h2o.clusterInfo(): 
## Your H2O cluster version is (8 months) old. There may be a newer version available.
## Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html</code></pre>
<p>Wir arbeiten mit den Datensätzen <code>Ames housing data</code> und
<code>Job attrition data</code>.</p>
<pre class="r"><code>library(modeldata)
dim(modeldata::attrition)</code></pre>
<pre><code>## [1] 1470   31</code></pre>
<pre class="r"><code>churn &lt;- attrition |&gt;
  mutate_if(is.ordered, .funs = factor, ordered = FALSE)
# Ames housing data
ames &lt;- AmesHousing::make_ames()
ames.h2o &lt;- as.h2o(ames)

# Job attrition data
#churn &lt;- mutate_if(attrition, is.ordered, .funs = #factor, ordered = FALSE)
#churn.h2o &lt;- as.h2o(churn)</code></pre>
</div>
<div id="daten-splitten" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Daten splitten</h2>
<p>Als Anforderung für unseren Algorithmus f(X) stellen wir, dass er
akurat zukünftige Werte, die auf einer Menge von Features basieren,
vorhersagt. Das nennt man Generalisierbarkeit unseres Algorithmus. Dafür
müssen wir unseren Datensatz in zweit Teile teilen:</p>
<ul>
<li><p>Trainingsdatensatz: Er entwickelt unsere Feature Menge, trainiert
unseren Algorithmus, passt Hyperparameter an, vergleicht Modelle und
entscheidet sich für ein finales.</p></li>
<li><p>Testdatensatz: Ist das finale Modell gewählt, so benutzen wir den
Testdatensatz, um die Performance zu bewerten, die wir als
Generalisierungsfehler bezeichnen.</p></li>
</ul>
<p>Wir splitten die Trainingsdaten - Testdaten für gewöhnlich im
Verhältnis 60 - 40, 70 - 30 oder 80 - 20 auf. Ist das Verhältnis zu
groß, so finden wir ein Modell, dass die Trainingsdaten sehr gut
anpasst, aber nicht generalisierbar ist (Overfitting). Die Testdaten
sind möglicherweise nicht repräsentativ für die Gesamtpopulation. Ist
der Testdatensatz zu groß, so können wertvolle Daten möglicherweise
nicht in das Modell aufgenommen werden, da sie dem Testdatensatz
zugeordnet sind und nicht im Trainingsdatensatz enthalten sind. Zu große
Trainingsdatensätze führen auch irgendwann nicht mehr zu zustzlichem
Informationsgewinn. Kleinere Sätze erhöhen auch die Geschwindigkeit.</p>
<p>Die zwei einfachsten Wege Daten in zwei zu teilen, sind die einfache
Zufallsauswahl und das geschichtete Sampling.</p>
<div id="einfaches-zufälliges-auswählen" class="section level3"
number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Einfaches
zufälliges Auswählen</h3>
<pre class="r"><code># Using base R
set.seed(123)  # for reproducibility
index_1 &lt;- sample(1:nrow(ames), round(nrow(ames) * 0.7))
train_1 &lt;- ames[index_1, ]
test_1  &lt;- ames[-index_1, ]

# Using caret package
set.seed(123)  # for reproducibility
index_2 &lt;- createDataPartition(ames$Sale_Price, p = 0.7, 
                               list = FALSE)
train_2 &lt;- ames[index_2, ]
test_2  &lt;- ames[-index_2, ]

# Using rsample package
set.seed(123)  # for reproducibility
split_1  &lt;- initial_split(ames, prop = 0.7)
train_3  &lt;- training(split_1)
test_3   &lt;- testing(split_1)

# Using h2o package
split_2 &lt;- h2o.splitFrame(ames.h2o, ratios = 0.7, 
                          seed = 123)
train_4 &lt;- split_2[[1]]
test_4  &lt;- split_2[[2]]</code></pre>
</div>
</div>
<div id="geschichtetes-sampling" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Geschichtetes
Sampling</h2>
<p>Wir können aber auch einen Datensatz so auswählen, dass unsere
Trainings- und Testdatensätze eine ähnliche Y Verteilung haben. Das
bietet sich an, wenn wir z.B. bei Klassifizierungsproblemen eine sehr
unbalanzierte Response Variable haben (in etwa 85% - 15%). Das
<em>rsample</em> Packet bietet hier eine sehr unkomplizierte Lösung.
Durch das Erzwingen von geschichtetem Sampling erzwingen wir hier
Datensätze, die eine ähnliche Verteilung der Response haben.</p>
<pre class="r"><code># orginal response distribution
table(churn$Attrition) %&gt;% prop.table()</code></pre>
<pre><code>## 
##        No       Yes 
## 0.8387755 0.1612245</code></pre>
<pre class="r"><code>## 
##        No       Yes 
## 0.8387755 0.1612245

# stratified sampling with the rsample package
set.seed(123)
split_strat  &lt;- initial_split(churn, prop = 0.7, 
                              strata = &quot;Attrition&quot;)
train_strat  &lt;- training(split_strat)
test_strat   &lt;- testing(split_strat)

# consistent response ratio between train &amp; test
table(train_strat$Attrition) %&gt;% prop.table()</code></pre>
<pre><code>## 
##        No       Yes 
## 0.8394942 0.1605058</code></pre>
<pre class="r"><code>## 
##       No      Yes 
## 0.838835 0.161165
table(test_strat$Attrition) %&gt;% prop.table()</code></pre>
<pre><code>## 
##        No       Yes 
## 0.8371041 0.1628959</code></pre>
<pre class="r"><code>## 
##        No       Yes 
## 0.8386364 0.1613636</code></pre>
</div>
<div id="modelle-erstellen" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Modelle
erstellen</h2>
<p>In R gibt es eine Vielzahl an leistungsstarken Algorithmen in
verschiedensten Paketen. Manche sind rechnerisch effizienter als andere,
manche sind flexibler. In den folgenden Kapiteln lernen wir verschieden
Algorithmen und Pakete für unterschiedliche Problemstellungen
kennen.</p>
</div>
<div id="resampling-methoden" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Resampling
Methoden</h2>
<p>Wir haben sehr explizit darauf hingewiesen, dass wir das Testset
während der Trainingsphase nicht verwenden, um die Leistung des Modells
zu bewerten. Wie bewerten wir also die Generalisierungsleistung des
Modells? Eine Option besteht darin, eine Fehlermetrik auf Grundlage der
Trainingsdaten zu bewerten. Leider führt dies zu verzerrten Ergebnissen,
da einige Modelle auf den Trainingsdaten sehr gut abschneiden, aber
nicht gut auf einem neuen Datensatz generalisieren können.</p>
<p>Eine zweite Methode ist die Verwendung eines Validierungsansatzes,
bei dem das Trainingsset weiter in zwei Teile aufgeteilt wird: ein
Trainingsset und ein Validierungsset (oder Holdout-Set). Wir können dann
unser Modell auf dem neuen Trainingsset trainieren und die Leistung auf
dem Validierungsset schätzen. Leider kann die Validierung mit einem
einzigen Holdout-Set sehr variabel und unzuverlässig sein, es sei denn,
Sie arbeiten mit sehr großen Datensätzen.</p>
<p>Resampling-Methoden bieten einen alternativen Ansatz, indem sie uns
ermöglichen, ein Modell von Interesse wiederholt an Teilen der
Trainingsdaten anzupassen und dessen Leistung auf anderen Teilen zu
testen. Die beiden am häufigsten verwendeten Resampling-Methoden sind
die k-fold-Kreuzvalidierung und das Bootstrap-Verfahren.</p>
</div>
<div id="k-fold-kreuzvalidierung" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> k-fold
Kreuzvalidierung</h2>
<p>Die k-Fach-Kreuzvalidierung (auch k-fold CV genannt) ist eine
Resampling-Methode, bei der die Trainingsdaten zufällig in k Gruppen
(auch Folds genannt) von ungefähr gleicher Größe aufgeteilt werden. Das
Modell wird auf k-1 Folds angepasst und dann wird der verbleibende Fold
verwendet, um die Leistung des Modells zu berechnen. Dieser Vorgang wird
k Mal wiederholt; jedes Mal wird ein anderer Fold als Validierungsset
behandelt. Dieser Prozess führt zu k Schätzungen des
Generalisierungsfehlers.</p>
<div class="float">
<img src="images/cv.png"
title="k-fold Kreuzvalidierungsprozess"
alt="k-fold Kreuzvalidierungsprozess" />
<div class="figcaption">k-fold Kreuzvalidierungsprozess</div>
</div>
<p>Folglich wird bei k-Fach-CV jede Beobachtung in den Trainingsdaten
einmal zurückgehalten und in das Testset einbezogen. Es gibt keine
formale Regel für die Größe von k; jedoch wird bei größerem k der
Unterschied zwischen der geschätzten Leistung und der tatsächlichen
Leistung, die im Testset zu sehen ist, abnehmen. Andererseits kann die
Verwendung eines zu großen k zu einer erhöhten Rechenlast führen.</p>
<div class="float">
<img
src="images/ten_fold_cv.png"
title="10-fold Kreuzvalidierungsprozess auf 32 Beobachtungen"
alt="10-fold Kreuzvalidierungsprozess auf 32 Beobachtungen" />
<div class="figcaption">10-fold Kreuzvalidierungsprozess auf 32
Beobachtungen</div>
</div>
<p>Wir werden verschiedene Möglichkeiten behandeln, wie man
Kreuzvalidierung (CV) einbeziehen kann. Wir benötigen einen Prozess, um
das ML-Modell auf jede Stichprobe anzuwenden.</p>
<pre class="r"><code>vfold_cv(ames, v = 10)</code></pre>
<pre><code>## #  10-fold cross-validation 
## # A tibble: 10 × 2
##    splits             id    
##    &lt;list&gt;             &lt;chr&gt; 
##  1 &lt;split [2637/293]&gt; Fold01
##  2 &lt;split [2637/293]&gt; Fold02
##  3 &lt;split [2637/293]&gt; Fold03
##  4 &lt;split [2637/293]&gt; Fold04
##  5 &lt;split [2637/293]&gt; Fold05
##  6 &lt;split [2637/293]&gt; Fold06
##  7 &lt;split [2637/293]&gt; Fold07
##  8 &lt;split [2637/293]&gt; Fold08
##  9 &lt;split [2637/293]&gt; Fold09
## 10 &lt;split [2637/293]&gt; Fold10</code></pre>
<div id="bootstrapping" class="section level3" number="2.6.1">
<h3><span class="header-section-number">2.6.1</span> Bootstrapping</h3>
<p>Eine Bootstrap-Stichprobe ist eine zufällige Stichprobe der Daten,
die mit Zurücklegen genommen wird. Eine Bootstrap-Stichprobe hat die
gleiche Größe wie der Originaldatensatz, aus dem sie konstruiert wurde.
Darüber hinaus wird die Bootstrap-Stichprobe ungefähr dieselbe
Verteilung von Werten enthalten (durch Farben dargestellt) wie der
Originaldatensatz.</p>
<div class="float">
<img
src="images/bootstrap-scheme.png"
title="Bootstrap" alt="Bootstrap" />
<div class="figcaption">Bootstrap</div>
</div>
<p>Wir können Bootstrap-Stichproben einfach mit
<code>rsample::bootstraps()</code> erstellen, wie im folgenden
Codeausschnitt dargestellt.</p>
<pre class="r"><code>bootstraps(ames, times = 10)</code></pre>
<pre><code>## # Bootstrap sampling 
## # A tibble: 10 × 2
##    splits              id         
##    &lt;list&gt;              &lt;chr&gt;      
##  1 &lt;split [2930/1062]&gt; Bootstrap01
##  2 &lt;split [2930/1076]&gt; Bootstrap02
##  3 &lt;split [2930/1066]&gt; Bootstrap03
##  4 &lt;split [2930/1045]&gt; Bootstrap04
##  5 &lt;split [2930/1087]&gt; Bootstrap05
##  6 &lt;split [2930/1108]&gt; Bootstrap06
##  7 &lt;split [2930/1075]&gt; Bootstrap07
##  8 &lt;split [2930/1078]&gt; Bootstrap08
##  9 &lt;split [2930/1053]&gt; Bootstrap09
## 10 &lt;split [2930/1067]&gt; Bootstrap10</code></pre>
</div>
</div>
<div id="bias-varianz-trade-off" class="section level2" number="2.7">
<h2><span class="header-section-number">2.7</span> Bias Varianz
trade-off</h2>
<p>Vorhersagefehler können in zwei wichtige Teilkomponenten unterteilt
werden: Fehler aufgrund von “Bias” und Fehler aufgrund von “Varianz”.
Oft gibt es einen Kompromiss zwischen der Fähigkeit eines Modells, Bias
und Varianz zu minimieren.</p>
<div id="bias" class="section level3" number="2.7.1">
<h3><span class="header-section-number">2.7.1</span> Bias</h3>
<p>Bias beschreibt den Unterschied zwischen der erwarteten (oder
durchschnittlichen) Vorhersage unseres Modells und dem korrekten Wert,
den wir vorhersagen möchten. Es misst, wie weit im Allgemeinen die
Vorhersagen eines Modells vom korrekten Wert entfernt sind und gibt uns
eine Vorstellung davon, wie gut ein Modell der zugrunde liegenden
Struktur der Daten entsprechen kann.<br />
Lineare Modelle sind klassische Beispiele für Modelle mit hoher
Verzerrung, da sie weniger flexibel sind und selten nicht-lineare,
nicht-monotone Beziehungen erfassen.</p>
<p>Wir müssen auch an Bias-Varianz in Bezug auf Resampling denken.
Modelle mit hoher Verzerrung werden selten von dem durch das Resampling
eingeführten Rauschen beeinflusst. Wenn ein Modell einen hohen Bias
aufweist, wird es eine Konsistenz in seiner Resampling-Leistung
aufweisen.</p>
<div class="float">
<img src="images/bias.png"
title="Bias" alt="Bias" />
<div class="figcaption">Bias</div>
</div>
</div>
<div id="varianz" class="section level3" number="2.7.2">
<h3><span class="header-section-number">2.7.2</span> Varianz</h3>
<p>Auf der anderen Seite wird der Fehler aufgrund von Varianz definiert
als die Variabilität der Vorhersage eines Modells für einen bestimmten
Datenpunkt. Viele Modelle (z. B. k-nearest neighbor, Entscheidungsbäume,
Gradient-Boosting-Maschinen) sind sehr anpassungsfähig und bieten eine
extreme Flexibilität in den Mustern, die sie anpassen können. Diese
Modelle bergen jedoch ihre eigenen Probleme, da sie Gefahr laufen, sich
an die Trainingsdaten anzupassen (Overfitting). Obwohl man auf den
Trainingsdaten eine sehr gute Leistung erzielen kann, wird das Modell
nicht automatisch gut auf unbekannte Daten generalisieren.</p>
<div class="float">
<img
src="images/variance_model.png"
title="Hohe Varianz bei k-nearest neighbour model"
alt="Hohe Varianz bei k-nearest neighbour model" />
<div class="figcaption">Hohe Varianz bei k-nearest neighbour model</div>
</div>
<p>Da Modelle mit hoher Varianz eher zu Overfitting neigen, sind
Resampling-Verfahren entscheidend, um dieses Risiko zu reduzieren.</p>
</div>
<div id="hyperparameter-anpassen" class="section level3" number="2.7.3">
<h3><span class="header-section-number">2.7.3</span> Hyperparameter
anpassen</h3>
<p>Hyperparameter (auch Abstimmungsparameter genannt) sind die „Knöpfe“,
mit denen die Komplexität von Machine-Learning-Algorithmen und somit das
Bias-Varianz-Trade-off gesteuert werden können. Nicht alle Algorithmen
haben Hyperparameter (z. B. die kleinsten Quadrate); die meisten haben
jedoch mindestens einen oder mehrere.</p>
<p>Die richtige Einstellung dieser Hyperparameter hängt oft von den
Daten und dem jeweiligen Problem ab und kann nicht immer allein durch
die Trainingsdaten geschätzt werden. Daher benötigen wir eine Methode
zur Identifizierung der optimalen Einstellung.</p>
<p>Als Beispiel nehmen wir das k-nearest neighbor Modell.
K-nächste-Nachbarn-Modelle haben einen einzelnen Hyperparameter (k), der
den vorhergesagten Wert auf Basis der k nächsten Beobachtungen im
Trainingsdatensatz bestimmt. Wenn k klein ist (z. B. k = 3), macht das
Modell eine Vorhersage für eine gegebene Beobachtung auf Basis des
Durchschnitts der Antwortwerte für die 3 Beobachtungen im
Trainingsdatensatz, die der zu vorhersagenden Beobachtung am ähnlichsten
sind. Dies führt oft zu sehr variablen Vorhersagewerten, weil wir die
Vorhersage (in diesem Fall einen Durchschnitt) auf eine sehr kleine
Teilmenge der Trainingsdaten stützen. Wenn k größer wird, stützen wir
unsere Vorhersagen auf einen Durchschnitt einer größeren Teilmenge der
Trainingsdaten, was natürlich die Varianz unserer Vorhersagewerte
reduziert. Kleinere k-Werte (z. B. 2, 5 oder 10) führen zu hoher Varianz
(aber geringerem Bias) und größere Werte (z. B. 150) führen zu hohem
Bias (aber geringerer Varianz). Der optimale k-Wert könnte irgendwo
zwischen 20 und 50 liegen, aber wie wissen wir, welchen k-Wert wir
verwenden sollen?</p>
<div class="float">
<img
src="images/knn_hyper.png"
title="knn-Modell mit verschiedenen Werten für k"
alt="knn-Modell mit verschiedenen Werten für k" />
<div class="figcaption">knn-Modell mit verschiedenen Werten für k</div>
</div>
<p>Eine Methode ist die Durchführung einer Rastersuche. Eine Rastersuche
ist eine automatisierte Methode, um viele Kombinationen von
Hyperparameter-Werten zu durchsuchen. Unter Verwendung von wiederholtem
10-fachem CV entspricht die Fehlerrate dem durchschnitllichen Fehler für
jeden Wert von k. Für k = 46 wird der Fehler minimiert (RMSE).</p>
<div class="float">
<img
src="images/RMSE_k.png"
title="grid search for knn for k = 2-150"
alt="grid search for knn for k = 2-150" />
<div class="figcaption">grid search for knn for k = 2-150</div>
</div>
</div>
</div>
<div id="modellbewertung" class="section level2" number="2.8">
<h2><span class="header-section-number">2.8</span> Modellbewertung</h2>
<p>Heutzutage ist es weithin akzeptiert, dass ein zuverlässigerer Ansatz
zur Bewertung der Modellleistung darin besteht, die
Vorhersagegenauigkeit über Verlustfunktionen zu bewerten.
Verlustfunktionen sind Metriken, die die vorhergesagten Werte mit dem
tatsächlichen Wert vergleichen (der Output einer Verlustfunktion wird
oft als Fehler oder Pseudo-Residuum bezeichnet). Bei Resampling-Methoden
bewerten wir die vorhergesagten Werte für einen Validierungssatz im
Vergleich zum tatsächlichen Zielwert. Zum Beispiel kann bei Regressionen
ein Weg, den Fehler zu messen, darin bestehen, die Differenz zwischen
dem tatsächlichen und dem vorhergesagten Wert für eine gegebene
Beobachtung zu nehmen. Der gesamte Validierungsfehler des Modells wird
berechnet, indem man die Fehler über den gesamten Validierungsdatensatz
aggregiert. Es gibt viele Verlustfunktionen zur Auswahl, um die Leistung
eines Vorhersagemodells zu bewerten, wobei jede eine einzigartige
Vorstellung von der Vorhersagegenauigkeit bietet und zwischen
Regressions- und Klassifikationsmodellen variiert.</p>
<div id="regressionsmodelle" class="section level3" number="2.8.1">
<h3><span class="header-section-number">2.8.1</span>
Regressionsmodelle</h3>
<p><strong>MSE</strong>: Mean Squared Error. <span
class="math inline">\(MSE = \frac{1}{n} \sum_{i=1}^n (y_i -
\hat{y}_i)^2.\)</span> <strong>Ziel</strong>: minimieren</p>
<p><strong>RMSE</strong>: <span class="math inline">\(RMSE =
\sqrt{MSE}\)</span>. <strong>Ziel</strong>: minimieren.</p>
<p><strong>Deviance</strong>: Es wird oft bei Klassifizierungsmodellen
benutzt. <strong>Ziel</strong>: minimieren.</p>
<p><strong>MAE</strong>: <span class="math inline">\(MAE = \frac{1}{n}
\sum_{i=1}^n (|y_i - \hat{y}_i|).\)</span> <strong>Ziel</strong>:
minimieren.</p>
<p><em>RMSLE</em>: Root mean squared logarithmic error. <span
class="math inline">\(RMSLE = \sqrt{\frac{1}{n} \sum^n_{i=1}(log(y_i +
1) - log(\hat y_i + 1))^2}\)</span>. <strong>Ziel</strong>:
minimieren.</p>
<p><span class="math inline">\(R^2\)</span>: <strong>Ziel</strong>:
maximieren.</p>
<p><span class="math inline">\(R^2\)</span> (R-Squared) und <span
class="math inline">\(MSE\)</span> (Mean Squared Error) sind beide Maße,
die verwendet werden, um die Genauigkeit von Regressionsmodellen zu
bewerten, aber sie messen unterschiedliche Aspekte der
Vorhersageleistung. Zusammenfassend kann man sagen, dass <span
class="math inline">\(MSE\)</span> die Qualität der Vorhersagen selbst
misst, während <span class="math inline">\(R^2\)</span> die Qualität des
Modells misst, um die Daten zu erklären. Ein gutes Modell hat sowohl
eine niedrige <span class="math inline">\(MSE\)</span> als auch einen
hohen <span class="math inline">\(R^2\)</span>-Wert.</p>
</div>
<div id="klassifizierungsmodelle" class="section level3" number="2.8.2">
<h3><span class="header-section-number">2.8.2</span>
Klassifizierungsmodelle</h3>
<p><strong>Misclassification</strong>: z.B. 13/90 falscher Klasse
zugeordnet (14%). <strong>Ziel</strong>: minimieren.</p>
<p><strong>Mean per class errror</strong>: Der Durchschnitt.
<strong>Ziel</strong>: minimieren.</p>
<p><strong>MSE</strong>: Mean squared error. Berechnet die Distanz zu 1
und quadriert. Sagt unser Modell Wahrscheinlichkeiten für A, B, C von
0.91, 0.07, 0.02 voraus, so ergibt sich für die richtige Antwort A:
<span class="math inline">\(MSE = 0.09^2 = 0.0081\)</span>. Für B und C
als richtige Antworten <span class="math inline">\(0.93^2\)</span> und
<span class="math inline">\(0.98^2\)</span>. <strong>Ziel</strong>:
minimieren.</p>
<p><strong>Log Loss/Deviance/Cross-entropy</strong>:
<strong>Ziel</strong>: minimieren.</p>
<p><strong>Gini Index</strong>: <strong>Ziel</strong>: minimieren.</p>
<p>Bei der Anwendung von Klassifikationsmodellen verwenden wir oft eine
Konfusionsmatrix (confusion matrix), um bestimmte Leistungsmaße zu
evaluieren. Eine confusion matrix ist einfach eine Matrix, die
tatsächliche kategoriale Stufen (oder Ereignisse) mit den vorhergesagten
kategorialen Stufen vergleicht.</p>
<div class="float">
<img
src="images/confusion_matrix.png"
title="confusion matrix" alt="Confusion matrix" />
<div class="figcaption">Confusion matrix</div>
</div>
<p>Weitere Bewertungen können vorgenommen werden.</p>
<p><strong>Accuracy</strong>: korrekt klassifiziert, z.B. <span
class="math inline">\(\frac{TP+TN}{total} = \frac{100+50}{165} =
0.91\)</span>. <strong>Ziel</strong>: maximieren.</p>
<p><strong>Precision</strong>: Wieviele der Vorhersagen, die wir gemacht
waren, waren wirklich korrekt. <span
class="math inline">\(\frac{TP}{TP+FP} = \frac{100}{100+10} =
0.91\)</span>. <strong>Ziel</strong>: maximieren.</p>
<p><strong>Sensitivity</strong>: Für das eintreffende Event haben wir
wieviele vorhergesagt? <span class="math inline">\(\frac{TP}{TP+FN} =
\frac{100}{100+5} = 0.95\)</span>. <strong>Ziel</strong>:
maximieren.</p>
<p><strong>Specificity</strong>: Wie gut werden non-events
klassifiziert? <span class="math inline">\(\frac{TN}{TN+FP} =
\frac{50}{50+10} = 0.83\)</span>. <strong>Ziel</strong>: maximieren.</p>
<div class="float">
<img
src="images/bsp_confusion_m.png"
title="Beispiel: confusion matrix" alt="Beispiel: Confusion matrix" />
<div class="figcaption">Beispiel: Confusion matrix</div>
</div>
<p><strong>AUC</strong>: Ein guter binärer Klassifikator hat eine hohe
Präzision (Precision) und Empfindlichkeit (Sensitivity). Das bedeutet,
dass der Klassifikator gut abschneidet, wenn er vorhersagt, ob ein
Ereignis eintritt oder nicht, was die Anzahl der falsch positiven und
falsch negativen Ergebnisse minimiert. Um dieses Gleichgewicht zu
erfassen, verwenden wir oft eine ROC-Kurve, die die Falsch-Positiv-Rate
entlang der x-Achse und die Wahre-Positiv-Rate entlang der y-Achse
darstellt. Eine Linie, die diagonal von der unteren linken Ecke zur
oberen rechten Ecke verläuft, repräsentiert eine zufällige Vermutung. Je
höher die Linie in der oberen linken Ecke ist, desto besser ist der
Klassifikator. Der AUC berechnet den Bereich unter dieser Kurve.</p>
<div class="float">
<img src="images/roc.png"
title="ROC Kurve" alt="ROC Kurve" />
<div class="figcaption">ROC Kurve</div>
</div>
</div>
</div>
<div id="alles-zusammenpacken" class="section level2" number="2.9">
<h2><span class="header-section-number">2.9</span> Alles
zusammenpacken</h2>
<p>Geschichtetes Sampling, um unsere Daten in Trainings- und
Testdatensatz zu brechen, während wir konsistente Vereteilungen zwischen
den Datensätzen haben. Unser Datensatz insgesamt:</p>
<pre class="r"><code>ames|&gt;
  ggplot(aes(x = Sale_Price)) +
  geom_histogram(aes(y = ..density..), colour = 1) + 
  geom_density(lwd = 1.2, linetype = 2, colour = 2)</code></pre>
<pre><code>## Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.
## ℹ Please use `after_stat(density)` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Jetzt nehmen wir die Aufteilung vor. In R sind
<code>createDataPartition()</code> und <code>initial_split()</code>
Funktionen in dem Paket caret enthalten, die für die Erstellung von
Trainings- und Testdatensätzen für Machine-Learning-Modelle verwendet
werden können.</p>
<p><strong>createDataPartition()</strong>: Diese Funktion teilt die
Daten basierend auf einer gegebenen Prozentsatzgröße in zwei Gruppen auf
(z. B. 70% für das Training und 30% für das Testen). Der Unterschied
besteht jedoch darin, dass es versucht, die Klassenverteilung innerhalb
der Daten zu berücksichtigen. Mit anderen Worten, es versucht, die
Proportionen der Zielklasse in beiden Gruppen (Training und Test)
beizubehalten.</p>
<p><strong>initial_split()</strong>: Diese Funktion teilt die Daten in
zwei Gruppen auf, ohne die Klassenverteilung innerhalb der Daten zu
berücksichtigen. Sie können den Prozentsatz für jede Gruppe angeben, z.
B. 80% für das Training und 20% für das Testen.</p>
<pre class="r"><code># Stratified sampling with the rsample package
set.seed(123)
split &lt;- initial_split(ames, prop = 0.7, 
                       strata = &quot;Sale_Price&quot;)
ames_train  &lt;- training(split)
ames_test   &lt;- testing(split)</code></pre>
<p>Als Nächstes werden wir einen k-nearest neighbor Regressor auf unsere
Daten anwenden. Dazu werden wir <strong>caret</strong> verwenden, das
eine Meta-Engine ist, um die Prozesse des Resamplings, der Rastersuche
und der Modellanwendung zu vereinfachen.</p>
<ol style="list-style-type: decimal">
<li><strong>Resampling</strong>: 10-fold CV, fünf mal wiederholt.</li>
<li><strong>Grid Search</strong>: Hyperparameter k = 2, 3, …, 25.</li>
<li><strong>Model training and Validation</strong>: Wir trainieren ein
knn Modell (<code>method = "knn"</code>) mit unserer Resampling
Prozedur(<code>trControl = cv</code>), Grid Search
(<code>tuneGrid = hyper_grid</code>) und unserer präferierte loss
function(<code>metric = "RMSE"</code>).</li>
</ol>
<pre class="r"><code># Specify resampling strategy
cv &lt;- trainControl(
  method = &quot;repeatedcv&quot;, 
  number = 10, 
  repeats = 5
)</code></pre>
<p>Hier wird ein Trainingskontroll-Objekt mit dem Namen “cv” erstellt,
das als Einstellung für die Durchführung der Kreuzvalidierung beim
Trainieren eines Machine-Learning-Modells verwendet werden kann.</p>
<p>method = “repeatedcv” gibt an, dass eine Kreuzvalidierung mit
wiederholten Durchläufen (repeated cross validation) durchgeführt werden
soll. Bei dieser Art der Kreuzvalidierung wird die
Datensatzpartitionierung in k-Folds (hier: 10-Folds) mehrmals
wiederholt, um eine robustere Schätzung der Modellgenauigkeit zu
erhalten.</p>
<p>number = 10 gibt an, dass der Datensatz in 10 Folds aufgeteilt werden
soll. In jedem Durchlauf wird ein Fold als Testdatensatz verwendet und
die restlichen 9 Folds als Trainingsdatensatz verwendet.</p>
<p>repeats = 5 gibt an, wie oft die Kreuzvalidierung mit 10-Folds
wiederholt werden soll, um eine robustere Schätzung der
Modellgenauigkeit zu erhalten. Insgesamt werden also 50 Durchläufe der
Kreuzvalidierung durchgeführt (10-Folds x 5 Wiederholungen).</p>
<p>Zusammenfassend führt das Erstellen des Trainingskontroll-Objekts mit
diesen Einstellungen zu einer robusten Schätzung der Modellgenauigkeit,
indem die Kreuzvalidierung mit wiederholten Durchläufen durchgeführt
wird. Dadurch können die hyperparameter des Machine-Learning-Modells
optimiert werden, indem verschiedene Kombinationen ausprobiert werden
und diejenige mit der besten Kreuzvalidierungsgenauigkeit ausgewählt
wird.</p>
<pre class="r"><code># Create grid of hyperparameter values
hyper_grid &lt;- expand.grid(k = seq(2, 25, by = 1))</code></pre>
<pre class="r"><code># Tune a knn model using grid search
library(caret)
knn_fit &lt;- train(
  Sale_Price ~ ., 
  data = ames_train, 
  method = &quot;knn&quot;, 
  trControl = cv, 
  tuneGrid = hyper_grid,
  metric = &quot;RMSE&quot;
)</code></pre>
<p>train ist eine Funktion in der R-Package “caret” und wird verwendet,
um Machine-Learning-Modelle zu trainieren. Die Funktion verwendet die
übergebenen Daten, um ein Modell mit den übergebenen Methoden zu
erstellen, wobei eine Kreuzvalidierung zur Modellauswahl und
Hyperparameter-Optimierung verwendet wird.</p>
<p>Hier wird train() verwendet, um ein k-NN-Modell zu trainieren. Dazu
werden folgende Parameter übergeben:</p>
<p><strong>Sale_Price ~ .</strong>: Formel, die angibt, dass Sale_Price
die abhängige Variable ist und alle anderen Variablen in ames_train die
unabhängigen Variablen sind. <strong>data = ames_train</strong>: Der
Trainingsdatensatz, der verwendet wird, um das Modell zu trainieren.
<strong>method = “knn”</strong>: Gibt an, dass ein k-NN-Modell verwendet
wird. <strong>trControl = cv</strong>: Das zuvor erstellte
Trainingskontroll-Objekt, das angibt, wie die Kreuzvalidierung
durchgeführt werden soll. <strong>tuneGrid = hyper_grid</strong>: Das
zuvor erstellte Dataframe, das alle möglichen Werte für den
hyperparameter k enthält. <strong>metric = “RMSE”</strong>: Gibt an,
dass die Root-Mean-Square-Error (RMSE) als Bewertungsmetrik für die
Kreuzvalidierung verwendet werden soll.</p>
<p>Die Funktion führt nun eine Kreuzvalidierung mit den angegebenen
Einstellungen durch, indem sie das k-NN-Modell mit verschiedenen Werten
von k trainiert und bewertet. Der beste Wert für k, der das beste
Ergebnis bei der Kreuzvalidierung liefert, wird verwendet, um das
endgültige Modell zu trainieren. Das trainierte Modell wird in der
Variablen knn_fit gespeichert.</p>
<pre class="r"><code>knn_fit
ggplot(knn_fit)</code></pre>
<p>Wenn wir uns die Ergebnisse ansehen, stellen wir fest, dass das beste
Modell mit k = 6 übereinstimmt, was zu einem RMSE von 43.846,05 führt.
Dies bedeutet, dass unser Modell im Durchschnitt den erwarteten
Verkaufspreis eines Hauses um 43.85 Dollar falsch vorhersagt.</p>
<p>Wir haben möglicherweise das optimale k-nearest neighbor-Modell für
unseren Datensatz identifiziert, aber das bedeutet nicht, dass wir das
insgesamt beste mögliche Modell gefunden haben.</p>
</div>
</div>
<div id="feature-and-target-engineering" class="section level1"
number="3">
<h1><span class="header-section-number">3</span> Feature and Target
Engineering</h1>
<p>Feature-Engineering und Target-Engineering beziehen sich auf den
Prozess der Manipulation und Transformation von Merkmalen (Features) und
dem Zielvariablen (Target) in einem Datensatz, um die Leistung von
Vorhersagemodellen zu verbessern. Feature-Engineering beinhaltet die
Identifikation, Extraktion und Umwandlung von Merkmalen, um sie für die
Verwendung in Machine-Learning-Modellen besser geeignet zu machen.
Target-Engineering bezieht sich auf die Modifikation des Zielmerkmals,
um es besser für die Vorhersage zu machen. Beide Prozesse können dazu
beitragen, die Genauigkeit und Leistung von Vorhersagemodellen zu
verbessern. Die Zeit, die für die Identifizierung von
Datenverarbeitungsanforderungen aufgewendet wird, kann erheblich sein
und erfordert, dass Sie erhebliche Zeit damit verbringen, Ihre Daten zu
verstehen.</p>
<div id="voraussetzungen-1" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Voraussetzungen</h2>
<pre class="r"><code>library(visdat)</code></pre>
<pre><code>## Warning: Paket &#39;visdat&#39; wurde unter R Version 4.2.3 erstellt</code></pre>
<pre class="r"><code>library(recipes) </code></pre>
<pre><code>## Warning: Paket &#39;recipes&#39; wurde unter R Version 4.2.3 erstellt</code></pre>
<pre><code>## 
## Attache Paket: &#39;recipes&#39;</code></pre>
<pre><code>## Das folgende Objekt ist maskiert &#39;package:stats&#39;:
## 
##     step</code></pre>
</div>
<div id="zielvariable" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Zielvariable</h2>
<p>Die Transformation der Zielvariable kann zu einer Verbesserung der
Vorhersage führen. Schauen wir uns bei der einfachen linearen Regression
die Residuen an. Diese können z.B. heavy tails haben und rechtsschief
sein.</p>
<pre class="r"><code>ames &lt;- AmesHousing::make_ames()
mdl &lt;- lm(Sale_Price~Year_Built, data = ames)
log.mdl &lt;- lm(log1p(Sale_Price) ~ log1p(Year_Built), data = ames)</code></pre>
<pre class="r"><code>ames|&gt;
  ggplot(aes(x = Year_Built, y = Sale_Price)) +
  geom_point()</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre class="r"><code>ames|&gt;
  ggplot(aes(x = Year_Built, y = Sale_Price)) +
  geom_point() +
  scale_x_log10() + scale_y_log10()</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-15-2.png" width="672" /></p>
<pre class="r"><code>ggplot(mdl, aes(x = .fitted, y = .resid)) +
   geom_point() +
   geom_hline(yintercept = 0, color = &quot;red&quot;)</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<pre class="r"><code>ggplot(log.mdl, aes(x = .fitted, y = .resid)) +
   geom_point() +
   geom_hline(yintercept = 0, color = &quot;red&quot;)</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-16-2.png" width="672" /></p>
<pre class="r"><code>ames|&gt;
  ggplot(aes(x = mdl$residuals)) +
  geom_histogram(fill = &quot;steelblue&quot;, color =    &quot;black&quot;) +
  labs(title = &quot;Histogram of Residuals&quot;, x = &quot;Residuals&quot;, y = &quot;Frequency&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<pre class="r"><code>ames|&gt;
  ggplot(aes(x = log.mdl$residuals)) +
  geom_histogram(fill = &quot;steelblue&quot;, color =    &quot;black&quot;) +
  labs(title = &quot;Histogram of Residuals&quot;, x = &quot;Residuals&quot;, y = &quot;Frequency&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>Das einfache Modell <span
class="math inline">\(\text{Sale_Price}=\beta_{0} + \beta_{1}
\text{Year_Built} + \epsilon\)</span> einen nimmt normalverteilten
Fehlerterm als Annahme an. Eine log Transformation kann schon hier
helfen diese Annahme zu erfüllen.</p>
<p>Es gibt zwei Hauptansätze, um zu helfen, positiv schief verteilte
Zielvariablen zu korrigieren.</p>
<ol style="list-style-type: decimal">
<li><p>Normalisierung Die meisten rechtsschiefen Verteilungen können so
transformiert werden, dass sie normalverteilt sind. Transformiere dafür
den Trainings- und Testdatensatz.</p></li>
<li><p>Benutze eine Box Cox Transformation.</p></li>
</ol>
</div>
<div id="umgang-mit-fehlenden-werten" class="section level2"
number="3.3">
<h2><span class="header-section-number">3.3</span> Umgang mit fehlenden
Werten</h2>
</div>
<div id="features-filtern" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Features filtern</h2>
</div>
<div id="numerische-merkmalskonstruktion" class="section level2"
number="3.5">
<h2><span class="header-section-number">3.5</span> numerische
Merkmalskonstruktion</h2>
<p>Dies bezieht sich auf den Prozess der Erstellung neuer numerischer
Merkmale aus vorhandenen Daten, um die Leistung von maschinellen
Lernmodellen zu verbessern. Dabei können z.B. vorhandene numerische
Variablen kombiniert oder transformiert werden, um neue Merkmale zu
erzeugen, die einen besseren Einblick in die zugrunde liegenden Muster
und Zusammenhänge der Daten bieten können.</p>
</div>
<div id="kategoriale-merkmalskonstruktion" class="section level2"
number="3.6">
<h2><span class="header-section-number">3.6</span> kategoriale
Merkmalskonstruktion</h2>
<p>Dabei handelt es sich um den Prozess, neue kategoriale Merkmale aus
vorhandenen Daten zu erstellen, um die Leistung von maschinellen
Lernmodellen zu verbessern. Hierbei können z.B. bestehende kategoriale
Variablen neu gruppiert, transformiert oder umkodiert werden, um neue
Merkmale zu erzeugen, die ein besseres Verständnis der zugrunde
liegenden Muster und Zusammenhänge der Daten ermöglichen.</p>
</div>
<div id="dimensionsreduktion" class="section level2" number="3.7">
<h2><span class="header-section-number">3.7</span>
Dimensionsreduktion</h2>
</div>
<div id="korrekteangemessene-umsetzung" class="section level2"
number="3.8">
<h2><span class="header-section-number">3.8</span> korrekte/angemessene
Umsetzung</h2>
</div>
</div>
<div id="lineare-regression" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Lineare Regression</h1>
<p>Die lineare Regression ist ein grundlegendes statistisches Modell und
einer der einfachsten Algorithmen für überwachtes Lernen. Obwohl es im
Vergleich zu einigen der moderneren statistischen Lernansätze, die in
späteren Kapiteln beschrieben werden, etwas langweilig erscheinen mag,
ist die lineare Regression immer noch eine nützliche und weit
verbreitete statistische Lernmethode. Außerdem dient sie als guter
Ausgangspunkt für fortschrittlichere Ansätze. Wie wir in späteren
Kapiteln sehen werden, können viele der anspruchsvolleren statistischen
Lernmethoden als Verallgemeinerungen oder Erweiterungen der einfachen
linearen Regression betrachtet werden. Daher ist es wichtig, ein gutes
Verständnis der linearen Regression zu haben, bevor man komplexere
Lernmethoden studiert.</p>
<div id="voraussetzungen-2" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Voraussetzungen</h2>
<pre class="r"><code># Modeling packages
library(caret)    # for cross-validation, etc.

# Model interpretability packages
library(vip)</code></pre>
<pre><code>## Warning: Paket &#39;vip&#39; wurde unter R Version 4.2.3 erstellt</code></pre>
<pre><code>## 
## Attache Paket: &#39;vip&#39;</code></pre>
<pre><code>## Das folgende Objekt ist maskiert &#39;package:utils&#39;:
## 
##     vi</code></pre>
</div>
<div id="schätzung-der-unbekannten-parameter" class="section level2"
number="4.2">
<h2><span class="header-section-number">4.2</span> Schätzung der
unbekannten Parameter</h2>
<p>Es gibt mehrere Möglichkeiten, um “beste Anpassung” zu messen, aber
das LS-Kriterium findet die “beste Anpassung” durch Minimierung der
Summe der quadratischen Abweichungen (RSS):</p>
<p><span class="math inline">\(RSS\left(\beta_0, \beta_1\right) =
\sum_{i=1}^n\left(Y_i - \beta_0 - \beta_1 X_i\right)^2.\)</span></p>
<p>In unserem Ames housing Datensatz können wir leicht eine lineare
Beziehung herstellen zwischen der Gesamtwohnfläche und dem
Verkaufspreis.</p>
<pre class="r"><code>model1 &lt;- lm(Sale_Price ~ Gr_Liv_Area, data = ames_train)</code></pre>
<p>Unser einfaches lineares Regressionsmodell/OLS hat also einen
y-Achsenabschnitt und einen Steigungsparameter.</p>
<p><span class="math display">\[\begin{equation}
  \widehat{Y}_{new} = \widehat{\beta}_0 + \widehat{\beta}_1 X_{new},
\end{equation}\]</span></p>
<pre class="r"><code>options(scipen = 999)
ames_train|&gt;
  mutate(predicted = predict(model1), residuals = residuals(model1)) |&gt;
  ggplot(aes(x = Gr_Liv_Area, y = Sale_Price)) +
  xlim(0, 6000) +
  ylim(0, 800000) +
  geom_smooth(method = &#39;lm&#39;, se = FALSE, color = &quot;lightgrey&quot;) +
  geom_segment(aes(xend = Gr_Liv_Area, yend = predicted), alpha = .2) +
  geom_point(aes(color = abs(residuals))) +
  scale_color_continuous(low = &quot;black&quot;, high = &quot;red&quot;) +
  scale_y_continuous(labels = scales::comma) +
  guides(color = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  ggtitle(&quot;Regressionsmodell mit \ngeschätzter Gerade und Residuen&quot;) +
  theme_bw() </code></pre>
<pre><code>## Scale for y is already present.
## Adding another scale for y, which will replace the existing scale.</code></pre>
<pre><code>## Warning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use &quot;none&quot; instead as
## of ggplot2 3.3.4.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.</code></pre>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Um einen deteillierten Report zu erhalten, können wir
<code>summary()</code> benutzen.</p>
<pre class="r"><code>summary(model1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Sale_Price ~ Gr_Liv_Area, data = ames_train)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -474682  -30794   -1678   23353  328183 
## 
## Coefficients:
##              Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept) 15938.173   3851.853   4.138            0.0000365 ***
## Gr_Liv_Area   109.667      2.421  45.303 &lt; 0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 56790 on 2047 degrees of freedom
## Multiple R-squared:  0.5007, Adjusted R-squared:  0.5004 
## F-statistic:  2052 on 1 and 2047 DF,  p-value: &lt; 0.00000000000000022</code></pre>
<p>Der durchschnittliche Verkaufspreis steigt also pro Quadratfuß um
114.88 Einheiten.<br />
Die Residuen sind die Differenz zwischen den beobachteten Response
Values und den vorhergesagten. Die Quantile geben einen schnellen
Überblick über ihre Verteiung. Der Standardfehler bei einer einfachen
linearen Regression misst die durchschnittliche Abweichung der
Koeffizientenschätzung für die Steigung von der tatsächlichen wahren
Steigung. In diesem Beispiel ist der Standardfehler für die Steigung des
Regressionsmodells 2.448. Das bedeutet, dass wir erwarten würden, dass
unsere Schätzung der Steigung um etwa 2.448 vom wahren Wert abweicht.
Mit anderen Worten, wenn wir das Modell mehrmals ausführen würden,
würden wir erwarten, dass die Schätzung der Steigung jedes Mal um etwa
diesen Betrag variiert. Der Koeffizient t-Wert ist ein Maß dafür, wie
viele Standardabweichungen unsere Koeffizientenschätzung von 0 entfernt
ist. Wir möchten, dass er weit von Null entfernt ist, da dies darauf
hinweist, dass wir die Nullhypothese ablehnen können.</p>
<p>Ein kleiner p-Wert deutet darauf hin, dass es unwahrscheinlich ist,
dass wir eine Beziehung zwischen den Prädiktor und der Response
Variablen aufgrund des Zufalls beobachten werden. Typischerweise ist ein
p-Wert von 5% oder weniger ein guter Grenzwert.</p>
<p>Der Standardfehler der Residuen ist ein Maß für die Qualität der
Anpassung einer linearen Regression. Theoretisch wird angenommen, dass
jedes lineare Modell einen Fehlerterm E enthält. Aufgrund des
Vorhandenseins dieses Fehlerterms sind wir nicht in der Lage, unsere
abhängige Variable aus unserer unabhängigen Variable perfekt
vorherzusagen. Der Standardfehler der Residuen ist der durchschnittliche
Betrag, um den die abhängige Variable von der wahren Regressionslinie
abweicht. Der Standardfehler der Residuen berechnet sich durch die
Wurzel der Varianz:</p>
<p><span class="math display">\[\begin{equation}
  \widehat{\sigma}^2 = \frac{1}{n - p}\sum_{i = 1} ^ n r_i ^ 2,
\end{equation}\]</span></p>
<p>Die Differenz zwischen den beobachteten und den vorhergesagten
y-Werten wird quadriert und aufsummiert. Freiheitsgrade sind n-p, also
der Stichprobenumfang weniger die Anzahl der geschätzten Parameter.</p>
<p><span class="math inline">\(\widehat{\sigma}^2\)</span> ist der MSE
und die Wurzel der RMSE, welcher in R durch <code>sigma()</code>
berechnet werden kann.</p>
<pre class="r"><code>sigma(model1)</code></pre>
<pre><code>## [1] 56787.94</code></pre>
<pre class="r"><code>sigma(model1)^2</code></pre>
<pre><code>## [1] 3224869786</code></pre>
<p>Das Konfidenzintervall für die Koeffizienten erhalten wir durch:</p>
<p><span class="math display">\[\begin{equation}
  \widehat{\beta}_j \pm t_{1 - \alpha / 2, n - p}
\widehat{SE}\left(\widehat{\beta}_j\right).
  \tag{4.3}
\end{equation}\]</span></p>
<p>In R durch:</p>
<pre class="r"><code>confint(model1, level = 0.95)</code></pre>
<pre><code>##                2.5 %     97.5 %
## (Intercept) 8384.213 23492.1336
## Gr_Liv_Area  104.920   114.4149</code></pre>
<p>Die R-Quadrat Statistik gibt an, wie gut das Modell die tatsächlichen
Daten abbildet. Sie wird als Anteil der Varianz angegeben und misst die
lineare Beziehung zwischen der unabhängigen Variable und der abhängigen
Variable. Der Wert von <span class="math inline">\(R^2\)</span> liegt
immer zwischen 0 und 1. Eine Zahl nahe bei 0 zeigt an, dass die
Regression die Varianz der abhängigen Variable nicht gut erklärt,
während eine Zahl nahe bei 1 bedeutet, dass die beobachtete Varianz der
abhängigen Variable gut erklärt wird.</p>
</div>
<div id="multiple-lineare-regression" class="section level2"
number="4.3">
<h2><span class="header-section-number">4.3</span> Multiple lineare
Regression</h2>
<p>In der Realität haben wir natürlich oft mehr als einen Prädiktor.
Hängt zum Beispiel Sale_Price ab von Gr_Liv_Area und Year_Built. Mit den
Prädiktoren: Jahr, in dem das Haus gebaut wurde und Bodenfläche in
Quadratfuß:</p>
<p><span class="math display">\[\begin{equation}
  Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon,
\end{equation}\]</span></p>
<p>wobei <span class="math inline">\(X_1\)</span> und <span
class="math inline">\(X_2\)</span> die interessierenden Features sind:
<span class="math inline">\(X_1\)</span> <code>Gr_Liv_Area</code> und
<span class="math inline">\(X_2\)</span> <code>Year_Built</code>.</p>
<pre class="r"><code>(model2 &lt;- lm(Sale_Price ~ Gr_Liv_Area + Year_Built, data = ames_train))</code></pre>
<pre><code>## 
## Call:
## lm(formula = Sale_Price ~ Gr_Liv_Area + Year_Built, data = ames_train)
## 
## Coefficients:
## (Intercept)  Gr_Liv_Area   Year_Built  
## -2102904.57        93.83      1086.85</code></pre>
<p>Wir können einen Contour Plot erstellen, der uns die Haupteffekte
anzeigt. Die Oberfläche ist flach, da nur Haupteffekte vorliegen. Hängt
der Effekt eines Prediktors von dem Auftreten anderer Prediktoren ab, so
liegt ein Interaction Effect vor. Sie können durch Produkte von Features
dargesellt werden. Eine Interaktion zwischen $X_1 = $
<code>Gr_Liv_Area</code> und $X_2 = $ <code>Year_Built</code> kann also
wie folgt drgestellt werden:</p>
<p><span class="math display">\[\begin{equation}
  Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_2 + \epsilon.
\end{equation}\]</span></p>
<p>In R kann eine Interaktion durch Doppelpunkte durchgeführt
werden.</p>
<pre class="r"><code>lm(Sale_Price ~ Gr_Liv_Area + Year_Built + Gr_Liv_Area:Year_Built, data = ames_train)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Sale_Price ~ Gr_Liv_Area + Year_Built + Gr_Liv_Area:Year_Built, 
##     data = ames_train)
## 
## Coefficients:
##            (Intercept)             Gr_Liv_Area              Year_Built  
##           -810498.3134               -728.5084                430.8755  
## Gr_Liv_Area:Year_Built  
##                 0.4168</code></pre>
<p>Zwei Contour Plots zeigen die Unterschiede zwischen “mit” und “ohne”
Interaktionseffekt auf.</p>
<div class="float">
<img
src="images/contour_reg.png"
title="Contour Plot - Multiple Regression"
alt="Contour Plot - Multiple Regression" />
<div class="figcaption">Contour Plot - Multiple Regression</div>
</div>
<p>Ein Modell mit nur Haupteffekten:</p>
<pre class="r"><code>model3 &lt;- lm(Sale_Price ~ ., data = ames_train) 
broom::tidy(model3)  </code></pre>
<pre><code>## # A tibble: 300 × 5
##    term                                     estimate std.error statistic p.value
##    &lt;chr&gt;                                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
##  1 (Intercept)                               -2.73e7 11016450.   -2.47    0.0134
##  2 MS_SubClassOne_Story_1945_and_Older        3.90e3     3575.    1.09    0.275 
##  3 MS_SubClassOne_Story_with_Finished_Atti…  -5.39e3    12164.   -0.443   0.658 
##  4 MS_SubClassOne_and_Half_Story_Unfinishe…  -4.41e2    13942.   -0.0316  0.975 
##  5 MS_SubClassOne_and_Half_Story_Finished_…   1.04e3     7250.    0.143   0.886 
##  6 MS_SubClassTwo_Story_1946_and_Newer       -6.67e3     5510.   -1.21    0.226 
##  7 MS_SubClassTwo_Story_1945_and_Older        1.57e3     6074.    0.259   0.795 
##  8 MS_SubClassTwo_and_Half_Story_All_Ages     3.41e3    10149.    0.336   0.737 
##  9 MS_SubClassSplit_or_Multilevel            -6.67e3    11673.   -0.571   0.568 
## 10 MS_SubClassSplit_Foyer                     1.49e3     7512.    0.199   0.843 
## # ℹ 290 more rows</code></pre>
</div>
<div id="bewertung-der-modelle" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Bewertung der
Modelle</h2>
<p>Wir haben jetzt drei verschiedene Modelle: ein Modell mit einem
Prädiktor, ein Modell mit zwei Features und ein Modell, in dem alle
Varianblen mit aufgenommen wurden.</p>
<p>Wir benutzen die RMSE Metrik und Cross-Validation, um das beste
Modell zu bestimmen. Wir können die Funktion <code>caret::train()</code>
verwenden, um ein lineares Modell (d.h. <code>method="lm"</code>) mit
Kreuzvalidierung zu trainieren. Der Vorteil von <strong>caret</strong>
besteht darin, dass es eingebaute Kreuzvalidierungsfunktionen bietet,
während die Funktion <code>lm()</code> dies nicht tut. Der folgende
Codeabschnitt verwendet caret::train(), um Modell1 mit 10-facher
Kreuzvalidierung neu anzupassen:</p>
<pre class="r"><code>set.seed(123)  # for reproducibility
(cv_model1 &lt;- train(
  form = Sale_Price ~ Gr_Liv_Area, 
  data = ames_train, 
  method = &quot;lm&quot;,
  trControl = trainControl(method = &quot;cv&quot;, number = 10)
))</code></pre>
<pre><code>## Linear Regression 
## 
## 2049 samples
##    1 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 1843, 1844, 1844, 1844, 1844, 1844, ... 
## Resampling results:
## 
##   RMSE      Rsquared  MAE     
##   56644.76  0.510273  38851.99
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE</code></pre>
<p>Wenn es auf unbekannte Daten angewendet wird, sind die Vorhersagen,
die dieses Modell macht, im Durchschnitt etwa $56.410,89 vom
tatsächlichen Verkaufspreis entfernt.</p>
<p>Schauen wir uns die anderen Modelle an:</p>
<pre class="r"><code># model 2 CV
set.seed(123)
cv_model2 &lt;- train(
  Sale_Price ~ Gr_Liv_Area + Year_Built, 
  data = ames_train, 
  method = &quot;lm&quot;,
  trControl = trainControl(method = &quot;cv&quot;, number = 10)
)

# model 3 CV
set.seed(123)
cv_model3 &lt;- train(
  Sale_Price ~ ., 
  data = ames_train, 
  method = &quot;lm&quot;,
  trControl = trainControl(method = &quot;cv&quot;, number = 10)
)</code></pre>
<pre><code>## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen</code></pre>
<pre class="r"><code>summary(resamples(list(
  model1 = cv_model1, 
  model2 = cv_model2, 
  model3 = cv_model3
)))</code></pre>
<pre><code>## 
## Call:
## summary.resamples(object = resamples(list(model1 = cv_model1, model2
##  = cv_model2, model3 = cv_model3)))
## 
## Models: model1, model2, model3 
## Number of resamples: 10 
## 
## MAE 
##            Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA&#39;s
## model1 34076.73 37656.23 39785.18 38851.99 40200.92 42058.68    0
## model2 29227.14 30885.17 32003.59 31695.48 32710.41 33942.26    0
## model3 14740.86 15377.88 17564.13 17559.41 19344.23 21180.02    0
## 
## RMSE 
##            Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA&#39;s
## model1 45604.65 55896.58 57000.74 56644.76 59544.08 66198.59    0
## model2 37174.26 42650.00 46869.84 46865.68 51155.14 55780.47    0
## model3 20737.09 24858.60 40515.19 41691.74 55969.21 69879.47    0
## 
## Rsquared 
##             Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## model1 0.4230788 0.4621034 0.5090642 0.5102730 0.5681246 0.5996400    0
## model2 0.5829425 0.6075293 0.6865871 0.6631008 0.6976664 0.7254572    0
## model3 0.5241423 0.6343368 0.7483874 0.7578796 0.9137443 0.9328876    0</code></pre>
<p>Wenn wir die Ergebnisse für jedes Modell betrachten, stellen wir
fest, dass wir durch das Hinzufügen weiterer Informationen über mehr
Prädiktoren die Metriken zur Leistungsbewertung der Kreuzvalidierung für
Out-of-Sample verbessern können. In dem Fall erzielt das Modell mit
allen möglichen Haupteffekten die “beste” Leistung (im Vergleich zu den
anderen beiden Modellen).</p>
</div>
<div id="model---bedenken" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> Model - Bedenken</h2>
<p>Es gibt einige Annahmen bei der linearen Regression, die oftmals
verletzt werden. Die Aufnahme von weiteren Variablen ist nicht
zweifelsfrei zu empfehlen. Eine Verletzung der Annahmen kann zu
fehlerhaften Interpretationen und Vorhersagen führen.</p>
<p><strong>1.Lineare Beziehung</strong> Wir gehen von einer linearen
Beziehung zwischen den unabhängigen und der abhängigen Variablen aus.
Nicht-lineare Beziehungen können jedoch durch Transformationen der a
oder/und ua Variablen in lineare Beziehungen umgewandelt werden. Durch
logarithmieren zum Beispiel. Hier wird y durch log transformiert.</p>
<pre class="r"><code>p1 &lt;- ggplot(ames_train, aes(Year_Built, Sale_Price)) + 
  geom_point(size = 1, alpha = .4) +
  geom_smooth(se = FALSE) +
  scale_y_continuous(&quot;Sale price&quot;, labels = scales::dollar) +
  xlab(&quot;Year built&quot;) +
  ggtitle(paste(&quot;Non-transformed variables with a\n&quot;,
                &quot;non-linear relationship.&quot;))

p2 &lt;- ggplot(ames_train, aes(Year_Built, Sale_Price)) + 
  geom_point(size = 1, alpha = .4) + 
  geom_smooth(method = &quot;lm&quot;, se = FALSE) +
  scale_y_log10(&quot;Sale price&quot;, labels = scales::dollar, 
                breaks = seq(0, 400000, by = 100000)) +
  xlab(&quot;Year built&quot;) +
  ggtitle(paste(&quot;Transforming variables can provide a\n&quot;,
                &quot;near-linear relationship.&quot;))

gridExtra::grid.arrange(p1, p2, nrow = 1)</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39;
## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p><strong>2.Konstante Varianz der Residuen</strong> Wenn die
Fehlervarianz nicht konstant ist, sind die p-Werte und
Konfidenzintervalle für die Koeffizienten ungültig. Ähnlich wie bei der
Annahme einer linearen Beziehung kann eine nicht konstante Varianz oft
durch Variablentransformationen oder durch Hinzufügen weiterer
Prädiktoren gelöst werden. Im Folgenden sehen wir die standardisierten
Residuen vs die vorhergesagten Werte unseres ersten und dritten Modells.
Nur ein Modell hat konstante Varianz.</p>
<pre class="r"><code>ggplot(data.frame(fitted(model1), residuals(model1)), aes(fitted(model1), residuals(model1))) + geom_point()</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<pre class="r"><code>df1 &lt;- broom::augment(cv_model1$finalModel, data = ames_train)

p1 &lt;- ggplot(df1, aes(.fitted, .std.resid)) + 
  geom_point(size = 1, alpha = .4) +
  xlab(&quot;Predicted values&quot;) +
  ylab(&quot;Residuals&quot;) +
  ggtitle(&quot;Model 1&quot;, subtitle = &quot;Sale_Price ~ Gr_Liv_Area&quot;)

df2 &lt;- broom::augment(cv_model3$finalModel, data = ames_train)

p2 &lt;- ggplot(df2, aes(.fitted, .std.resid)) + 
  geom_point(size = 1, alpha = .4)  +
  xlab(&quot;Predicted values&quot;) +
  ylab(&quot;Residuals&quot;) +
  ggtitle(&quot;Model 3&quot;, subtitle = &quot;Sale_Price ~ .&quot;)

gridExtra::grid.arrange(p1, p2, nrow = 1)</code></pre>
<pre><code>## Warning: Removed 20 rows containing missing values (`geom_point()`).</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-32-2.png" width="672" /></p>
<p><strong>3.Keine Autokorrelation</strong> Die lineare Regression geht
davon aus, dass die Fehler unabhängig und unkorreliert sind. Es besteht
ein deutliches Muster, das darauf hindeutet, dass Informationen über ϵ1
Informationen über ϵ2 liefern. Dieses Muster resultiert daraus, dass die
Daten nach Nachbarschaft sortiert sind, was wir in diesem Modell nicht
berücksichtigt haben. Folglich sind die Residuen für Häuser in derselben
Nachbarschaft korreliert (Häuser in einer Nachbarschaft sind in der
Regel gleich groß und können oft ähnliche Merkmale aufweisen). Da der
Nachbarschaftsprädiktor in Modell 3 enthalten ist (rechtes Diagramm),
wird die Korrelation in den Fehlern reduziert.</p>
<pre class="r"><code>df1 &lt;- mutate(df1, id = row_number())
df2 &lt;- mutate(df2, id = row_number())

p1 &lt;- ggplot(df1, aes(id, .std.resid)) + 
  geom_point(size = 1, alpha = .4) +
  xlab(&quot;Row ID&quot;) +
  ylab(&quot;Residuals&quot;) +
  ggtitle(&quot;Model 1&quot;, subtitle = &quot;Correlated residuals.&quot;)

p2 &lt;- ggplot(df2, aes(id, .std.resid)) + 
  geom_point(size = 1, alpha = .4) +
  xlab(&quot;Row ID&quot;) +
  ylab(&quot;Residuals&quot;) +
  ggtitle(&quot;Model 3&quot;, subtitle = &quot;Uncorrelated residuals.&quot;)

gridExtra::grid.arrange(p1, p2, nrow = 1)</code></pre>
<pre><code>## Warning: Removed 20 rows containing missing values (`geom_point()`).</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p><strong>4.Keine Multikollinearität</strong> Multikollinearität
bezieht sich auf die Situation, in der zwei oder mehr Prädiktorvariablen
eng miteinander verbunden sind. Das Vorhandensein von Multikollinearität
kann bei der OLS-Analyse Probleme verursachen, da es schwierig sein
kann, die individuellen Effekte kollinearer Variablen auf die
Antwortvariable zu trennen. Tatsächlich kann Multikollinearität dazu
führen, dass Prädiktorvariablen statistisch insignifikant erscheinen,
obwohl sie tatsächlich signifikant sind. Dies führt offensichtlich zu
einer ungenauen Interpretation der Koeffizienten und erschwert die
Identifizierung einflussreicher Prädiktoren.</p>
<p>In Ames haben beispielsweise die Variablen Garage_Area und
Garage_Cars eine Korrelation von 0,89, und beide Variablen sind eng mit
unserer Antwortvariablen (Sale_Price) verbunden. Wenn wir unser
vollständiges Modell betrachten, in dem beide Variablen enthalten sind,
sehen wir, dass Garage_Cars statistisch signifikant ist, aber
Garage_Area nicht:</p>
<pre class="r"><code>summary(cv_model3) |&gt;
  broom::tidy() |&gt;
  filter(term %in% c(&quot;Garage_Area&quot;, &quot;Garage_Cars&quot;))</code></pre>
<pre><code>## # A tibble: 2 × 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 Garage_Cars   3151.    1733.        1.82  0.0693
## 2 Garage_Area     11.9      5.69      2.10  0.0359</code></pre>
<p>Wenn wir ohne <code>Garage_Cars</code> refitten, dann ist
<code>Garage_Area</code> hoch signifikant.</p>
<pre class="r"><code>set.seed(123)
mod_wo_Garage_Cars &lt;- train(
  Sale_Price ~ ., 
  data = select(ames_train, -Garage_Cars), 
  method = &quot;lm&quot;,
  trControl = trainControl(method = &quot;cv&quot;, number = 10)
)</code></pre>
<pre><code>## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen

## Warning in predict.lm(modelFit, newdata): Vorhersage durch Fit ohne vollen Rang
## mag täuschen</code></pre>
<pre class="r"><code>summary(mod_wo_Garage_Cars) |&gt;
  broom::tidy() |&gt;
  filter(term == &quot;Garage_Area&quot;)</code></pre>
<pre><code>## # A tibble: 1 × 5
##   term        estimate std.error statistic    p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;
## 1 Garage_Area     19.4      3.96      4.89 0.00000109</code></pre>
<p>Dies spiegelt die Instabilität im linearen Regressionsmodell wider,
die durch Beziehungen zwischen Prädiktoren verursacht wird.</p>
<p>Darüber hinaus kann Multikollinearität auftreten, wenn ein Merkmal
linear mit zwei oder mehr Merkmalen zusammenhängt (was schwieriger zu
erkennen ist). In diesen Fällen ist eine manuelle Entfernung bestimmter
Prädiktoren möglicherweise nicht möglich. Infolgedessen bietet der
folgende Abschnitt zwei einfache Erweiterungen der linearen Regression
an, bei denen die Dimensionsreduzierung vor der Durchführung der
linearen Regression angewendet wird.</p>
</div>
<div id="principal-component-regression-pcr" class="section level2"
number="4.6">
<h2><span class="header-section-number">4.6</span> Principal Component
Regression (PCR)</h2>
<p>Es kann die Hauptkomponentenanalyse verwendet werden, um korrelierte
Variablen mit einer geringeren Anzahl unkorrelierter Merkmale (genannt
Hauptkomponenten) darzustellen, und die resultierenden Komponenten
können als Prädiktoren in einem linearen Regressionsmodell verwendet
werden. Dieser zweistufige Prozess wird als Hauptkomponentenregression
(PCR) bezeichnet.</p>
<div class="float">
<img src="images/pcr.png"
title="Principal Component Regression"
alt="Principal Component Regression" />
<div class="figcaption">Principal Component Regression</div>
</div>
<p>Die Durchführung von PCR mit Caret ist eine einfache Erweiterung
unseres vorherigen Modells. Wir geben einfach
<code>"method = "pcr"</code> innerhalb von <code>train()</code> an, um
eine PCA für alle unsere numerischen Prädiktoren durchzuführen. Du
kannst einen signifikanten Rückgang des Vorhersagefehlers im Vergleich
zu unseren vorherigen linearen Modellen erkennen, indem wir nur fünf
Hauptkomponenten verwenden, gefolgt von einem allmählichen Abfall
danach. Du wirst jedoch feststellen, dass es alle 100 Hauptkomponenten
benötigt, um einen minimalen RMSE zu erreichen.</p>
<pre class="r"><code># perform 10-fold cross validation on a PCR model tuning the 
# number of principal components to use as predictors from 1-100
set.seed(123)
cv_model_pcr &lt;- train(
  Sale_Price ~ ., 
  data = ames_train, 
  method = &quot;pcr&quot;,
  trControl = trainControl(method = &quot;cv&quot;, number = 10),
  preProcess = c(&quot;zv&quot;, &quot;center&quot;, &quot;scale&quot;),
  tuneLength = 100
  )

# model with lowest RMSE
cv_model_pcr$bestTune</code></pre>
<pre><code>##     ncomp
## 100   100</code></pre>
<pre class="r"><code>##    ncomp
## 97    97

# results for model with lowest RMSE
cv_model_pcr$results %&gt;%
  dplyr::filter(ncomp == pull(cv_model_pcr$bestTune))</code></pre>
<pre><code>##   ncomp     RMSE  Rsquared      MAE  RMSESD RsquaredSD    MAESD
## 1   100 32522.85 0.8352098 20446.33 7017.74 0.06480652 1735.195</code></pre>
<pre class="r"><code>##   ncomp     RMSE  Rsquared      MAE   RMSESD RsquaredSD    MAESD
## 1    97 30135.51 0.8615453 20143.42 5191.887 0.03764501 1696.534

# plot cross-validated RMSE
ggplot(cv_model_pcr)</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<p>Durch die Kontrolle der Multikollinearität mit PCR können wir im
Vergleich zu den zuvor erhaltenen linearen Modellen eine signifikante
Verbesserung unserer Vorhersagegenauigkeit erfahren (eine Reduktion der
kreuzvalidierten RMSE auf fast $30.000).</p>
<p>Es ist wichtig zu beachten, dass PCR ein zweistufiger Prozess ist,
bei dem der PCA-Schritt keine Aspekte der Antwort berücksichtigt, wenn
er die Komponenten auswählt. Es versucht lediglich, die Variabilität im
Prädiktorraum zu reduzieren. Wenn diese Variabilität mit der
Variabilität der Antwort zusammenhängt, hat PCR eine gute Chance, eine
Vorhersagebeziehung zu identifizieren, wie in unserem Fall. Wenn die
Variabilität im Prädiktorraum jedoch nicht mit der Variabilität der
Antwort zusammenhängt, kann es schwierig sein, eine Vorhersagebeziehung
zu identifizieren, wenn tatsächlich eine vorhanden ist. Ein alternativer
Ansatz zur Reduzierung des Einflusses der Multikollinearität ist die
partielle kleinste Quadrate (PLS).</p>
</div>
<div id="partial-least-squares-pls" class="section level2" number="4.7">
<h2><span class="header-section-number">4.7</span> Partial Least Squares
(PLS)</h2>
<p>PLS kann als überwachte Verfahren zur Dimensionsreduzierung
betrachtet werden. Ähnlich wie bei PCR konstruiert diese Technik auch
eine Reihe von linearen Kombinationen der Eingangsvariablen für die
Regression, aber im Gegensatz zu PCR wird die Response-Variable zur
Unterstützung der Konstruktion der Hauptkomponenten verwendet. Somit
können wir PLS als überwachtes Verfahren zur Dimensionsreduzierung
betrachten, das neue Merkmale findet, die nicht nur den größten Teil der
Informationen in den ursprünglichen Merkmalen erfassen, sondern auch mit
der Response-Variable zusammenhängen.</p>
<div class="float">
<img src="images/pls.png"
title="PLS" alt="Partial Least Squares Regression" />
<div class="figcaption">Partial Least Squares Regression</div>
</div>
<p>Ähnlich wie bei PCR können wir leicht ein PLS-Modell anpassen, indem
wir das Methodenargument in <code>train()</code> ändern. Wie bei PCR ist
die Anzahl der Hauptkomponenten, die verwendet werden sollen, ein
Abstimmungsparameter, der durch das Modell bestimmt wird, das die beste
Vorhersagegenauigkeit erzielt (in diesem Fall den RMSE minimiert).</p>
<pre class="r"><code># perform 10-fold cross validation on a PLS model tuning the 
# number of principal components to use as predictors from 1-30
set.seed(123)
cv_model_pls &lt;- train(
  Sale_Price ~ ., 
  data = ames_train, 
  method = &quot;pls&quot;,
  trControl = trainControl(method = &quot;cv&quot;, number = 10),
  preProcess = c(&quot;zv&quot;, &quot;center&quot;, &quot;scale&quot;),
  tuneLength = 30
)

# model with lowest RMSE
cv_model_pls$bestTune</code></pre>
<pre><code>##   ncomp
## 3     3</code></pre>
<pre class="r"><code>##    ncomp
## 20    20

# results for model with lowest RMSE
cv_model_pls$results %&gt;%
  dplyr::filter(ncomp == pull(cv_model_pls$bestTune))</code></pre>
<pre><code>##   ncomp     RMSE  Rsquared      MAE   RMSESD RsquaredSD    MAESD
## 1     3 31077.42 0.8493617 19137.51 7878.004 0.07079317 1784.467</code></pre>
<pre class="r"><code>##   ncomp     RMSE  Rsquared      MAE   RMSESD RsquaredSD   MAESD
## 1    20 25459.51 0.8998194 16022.68 5243.478 0.04278512 1665.61

# plot cross-validated RMSE
ggplot(cv_model_pls)</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
</div>
<div id="interpretation-der-feature" class="section level2"
number="4.8">
<h2><span class="header-section-number">4.8</span> Interpretation der
Feature</h2>
<p>Die Bedeutung der Variablen zielt darauf ab, diejenigen Variablen zu
identifizieren, die in unserem Modell am einflussreichsten sind. Bei
linearen Regressionsmodellen wird dies in der Regel durch den absoluten
Wert der t-Statistik für jeden verwendeten Modellparameter gemessen.
Obwohl dies einfach ist, können die Ergebnisse schwer interpretierbar
sein, wenn das Modell Wechselwirkungseffekte und komplexe
Transformationen enthält. Bei einem PLS-Modell kann die Bedeutung der
Variablen mithilfe der gewichteten Summen der absoluten
Regressionskoeffizienten berechnet werden. Die Gewichte sind eine
Funktion der Reduktion des RSS (Residual Sum of Squares) über die Anzahl
der PLS-Komponenten und werden separat für jede abhängige Variable
berechnet. Daher werden die Beiträge der Koeffizienten proportional zur
Reduktion des RSS gewichtet.</p>
<p>Wir können vip::vip() verwenden, um die wichtigsten Variablen zu
extrahieren und zu visualisieren. Das Bedeutungsmaß wird von 100 (am
wichtigsten) auf 0 (am wenigsten wichtig) normiert.</p>
<pre class="r"><code>vip(cv_model_pls, num_features = 20, method = &quot;model&quot;)</code></pre>
<pre><code>## Warning: Paket &#39;pls&#39; wurde unter R Version 4.2.3 erstellt</code></pre>
<pre><code>## 
## Attache Paket: &#39;pls&#39;</code></pre>
<pre><code>## Das folgende Objekt ist maskiert &#39;package:caret&#39;:
## 
##     R2</code></pre>
<pre><code>## Das folgende Objekt ist maskiert &#39;package:stats&#39;:
## 
##     loadings</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>Partial Dependence Plots (PDPs) helfen zu veranschaulichen wie sich
eine feste lineare Änderung von x in einer festen linearen Änderung von
y verhält und dabei die durchschnittliche Wirkung aller anderen Merkmale
im Modell berücksichtigt wird (bei linearen Modellen entspricht die
Steigung des PDPs dem entsprechenden Merkmal des OLS-Koeffizienten).</p>
<pre class="r"><code>pdp::partial(cv_model_pls, &quot;Gr_Liv_Area&quot;, grid.resolution = 20, plot = TRUE)</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<pre class="r"><code>pdp::partial(cv_model_pls, &quot;Total_Bsmt_SF&quot;, grid.resolution = 20, plot = TRUE)</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-39-2.png" width="672" /></p>
<pre class="r"><code>pdp::partial(cv_model_pls, &quot;First_Flr_SF&quot;, grid.resolution = 20, plot = TRUE)</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-39-3.png" width="672" /></p>
<pre class="r"><code>pdp::partial(cv_model_pls, &quot;Garage_Area&quot;, grid.resolution = 20, plot = TRUE)</code></pre>
<p><img src="index_3_files/figure-html/unnamed-chunk-39-4.png" width="672" /></p>
</div>
</div>
<div id="logistische-regression" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Logistische
Regression</h1>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
